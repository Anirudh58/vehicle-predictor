{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a8f78-b4ed-433a-b4d9-3d00426e1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append('./../')\n",
    "from src.dataset import VehiclePredictorDataset\n",
    "from src.utils import train_model, evaluate_model, get_model, visualize_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08438f-2b23-4dd4-864a-59fc0ebc7dea",
   "metadata": {},
   "source": [
    "## GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c450427-87df-46ab-bdf1-3acf59608996",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d61d102-0487-4aad-8af7-ac99ceca3aa7",
   "metadata": {},
   "source": [
    "## Config Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dff7a1-72d7-444b-9611-4ada42092331",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './../'\n",
    "data_path = os.path.join(root_path, 'data')\n",
    "dataset_path = os.path.join(data_path, 'VMMRdb')\n",
    "\n",
    "# modify this line if you want to train a model on top 100/top 200/top 300 most common make_models\n",
    "with open(os.path.join(data_path, 'make_model_year_most_common_100.pkl'), 'rb') as f:\n",
    "    target_make_model_year_labels = pickle.load(f)\n",
    "\n",
    "# load the dataset for some stats\n",
    "vp_dataset = VehiclePredictorDataset(root_dir=dataset_path, target_make_model_year_labels=target_make_model_year_labels)\n",
    "num_images = len(vp_dataset)\n",
    "num_labels = len(vp_dataset.make_model_year_counts)\n",
    "class_distribution = vp_dataset.make_model_year_counts\n",
    "print(f\"num_images: {num_images}\")\n",
    "print(f\"num_labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3f280-07f2-4e7b-8126-aefe5e82c0bf",
   "metadata": {},
   "source": [
    "## Define the transforms\n",
    "- Add other transforms here later, if needed. \n",
    "- Do we need any specific transforms for train and val?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0f001-93b7-46f7-80a5-48f7d15eb4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e66e4-8b06-4247-88be-780925b37760",
   "metadata": {},
   "source": [
    "## Instantiate the train, val and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36818fe0-473f-4210-847e-fc05acea41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_ratio = 0.8\n",
    "val_split_ratio = 0.1\n",
    "test_split_ration = 0.1\n",
    "\n",
    "# later see if you can have train-specific transforms\n",
    "dataset = VehiclePredictorDataset(root_dir=dataset_path, target_make_model_year_labels=target_make_model_year_labels, transform=get_transform())\n",
    "\n",
    "# split dataset in train and val set\n",
    "dataset_len = len(dataset)\n",
    "indices = torch.randperm(dataset_len).tolist()\n",
    "train_split_index = int(train_split_ratio * dataset_len)\n",
    "val_split_index = train_split_index + int(val_split_ratio * dataset_len)\n",
    "train_dataset = torch.utils.data.Subset(dataset, indices[0:train_split_index])\n",
    "val_dataset = torch.utils.data.Subset(dataset, indices[train_split_index:val_split_index])\n",
    "test_dataset = torch.utils.data.Subset(dataset, indices[val_split_index:])\n",
    "\n",
    "# define the dataloaders\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset),\n",
    "    'test': len(val_dataset)\n",
    "}\n",
    "\n",
    "print(f'train: 0 to {train_split_index}\\nval: {train_split_index} to {val_split_index}\\ntest: {val_split_index} to {dataset_len-1}')\n",
    "print(f'dataset_sizes : {dataset_sizes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d6173b-8610-4afe-990c-3b7d4d6172f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6737130-151b-49ae-8577-b152e1d0776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check https://pytorch.org/vision/0.8/models.html to experiment with other backbone model\n",
    "backbone_model = 'resnet18'\n",
    "num_epochs = 10\n",
    "\n",
    "# get the model\n",
    "model = get_model(num_labels, backbone_model).to(device)\n",
    "\n",
    "# the reason for computing weights is to account for the class imbalance\n",
    "weight_distribution = 1 / torch.tensor(list(class_distribution.values()))\n",
    "weight_distribution = weight_distribution / weight_distribution.sum()\n",
    "weight_distribution = weight_distribution.to(device)\n",
    "\n",
    "# define the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weight_distribution)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# define the scheduler\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model_info = {\n",
    "    'backbone': backbone_model,\n",
    "    'num_classes': f\"{num_labels}classes\",\n",
    "    'num_epochs': f\"{num_epochs}epochs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515b8b5-07a4-4837-9f76-58dbd31ede24",
   "metadata": {},
   "source": [
    "## Train\n",
    "- Uncomment this line if you want to train again. \n",
    "- The trained models are all stored in this [drive folder]( https://drive.google.com/drive/folders/1RXaKgStTFnVRaLvk-eIHEGhwvQp-y1-c?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5f1f5-effe-4e5a-b099-07457edd2857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model(model, model_info, dataset_sizes, dataloader_train, dataloader_val, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59e5c3-76ca-4a6e-ae0f-7f4851ac6e49",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2988f05-cdb9-42e6-a70e-2a60245121ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "model_name = 'mobilenet_v2_300classes_10epochs.pth'\n",
    "backbone_model = 'mobilenet_v2'\n",
    "model = get_model(num_labels, backbone_model).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(root_path, 'models', model_name)))\n",
    "\n",
    "cm, cr = evaluate_model(model, dataset_sizes, dataloader_test, target_make_model_labels)\n",
    "\n",
    "# plot the CM\n",
    "cm_pd = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_pd = pd.DataFrame(cm_pd, index=target_make_model_labels, columns=target_make_model_labels)\n",
    "cr_pd = pd.DataFrame(cr).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deddef57-75e2-4abe-9ecc-2bf416177a4f",
   "metadata": {},
   "source": [
    "- Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb12bf4-2520-494d-9219-e3b63e9222e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb01c9-0eed-447e-9bcc-e1a7b5f19941",
   "metadata": {},
   "source": [
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0946370-5849-4b25-a207-a8670171da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1845560-7130-4d60-ad6e-1a298c863079",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Save/Load the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c770ca29-128c-4130-83f2-546b2e0981ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_pd.to_csv(os.path.join(root_path, 'results', 'baseline_methods', f\"confusion_matrix_{model_name}.csv\"), index=False)\n",
    "cr_pd.to_csv(os.path.join(root_path, 'results', 'baseline_methods', f\"classification_report_{model_name}.csv\"), index=False)\n",
    "#cm_pd_df = pd.read_csv(os.path.join(root_path, 'results', 'baseline_methods', f\"confusion_matrix_{model_name}.csv\"))\n",
    "#cr_pd_df = pd.read_csv(os.path.join(root_path, 'results', 'baseline_methods', f\"classification_report_{model_name}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6fc8b6-0d4d-4ded-b33f-f01ac860d61a",
   "metadata": {},
   "source": [
    "## Visually Inspect performance\n",
    "- Load a target model to inpect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5d5a8-481d-458f-b6b2-ccfc7e5a42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "model = get_model(num_labels, backbone_model).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(root_path, 'models', model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac6d27-664e-4ba2-800c-1fde9a169fba",
   "metadata": {},
   "source": [
    "- Visualize for a few examples from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a7a31-a4a2-4315-a4c4-a6f3004acd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, dataset, dataloader_test, target_make_model_labels, num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e0034-c455-470a-9fa4-e550d5e6ef72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
